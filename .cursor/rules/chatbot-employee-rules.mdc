---
description:
globs:
alwaysApply: true
---

# AI Compliance & Employee Assistant — Project Guide

This project is an internal AI assistant to help employees with HR, tax, EPF/ETF, and other compliance-related queries. It uses **RAG (Retrieval-Augmented Generation)** with your collected documents and provides a chatbot + dashboard experience.

---

## 🚀 Project Structure

```
employee-assistant-ai/
│── backend/                # FastAPI backend (chat, RAG pipeline, auth)
│   ├── main.py
│   ├── rag/
│   │   ├── ingest.py       # Document ingestion & embedding
│   │   ├── query.py        # RAG query logic
│   │   ├── vectorstore/    # Vector DB (Chroma/FAISS)
│   └── requirements.txt
│
│── frontend/               # React (Next.js) frontend with chatbot UI + dashboard
│   ├── pages/
│   ├── components/
│   ├── package.json
│
│── data/                   # Source docs (PDFs, DOCX, FAQs)
│   ├── raw/                # Original uploaded docs
│   ├── processed/          # Cleaned & extracted text
│
│── scripts/                # Helper scripts
│   ├── convert_docs.py
│
│── README.md               # Main project readme
│── project_guide.md        # This file
```

---

## 📌 Step A — Gather & Prepare Content (DATA)

1. Collect all relevant files: HR policies, tax docs, EPF/ETF guides, sample forms.  
2. Record metadata for each doc (title, type, effective_date, source_url, confidentiality).  
3. Convert files into text:  
   - **PDFs** → `pdfplumber` or `PyMuPDF`  
   - **DOCX** → `python-docx`  
   - **Images** → `pytesseract` (OCR)  

Save extracted text in `data/processed/`.  

---

## 📌 Step B — Build RAG Pipeline

1. **Embed documents**:  
   - Use `sentence-transformers` (e.g., `all-MiniLM-L6-v2`).  
   - Store embeddings in a vector database (`ChromaDB` or `FAISS`).  

2. **Query workflow**:  
   - User → Question → Retrieve top-k docs → Send to LLM (OpenAI/GPT or LLaMA).  
   - LLM answers with citations (source docs).  

---

## 📌 Step C — Backend API (FastAPI)

Endpoints:
- `/chat` → POST user query, return chatbot answer.  
- `/ingest` → Upload new docs, process into embeddings.  
- `/health` → Service health check.  

Dependencies in `requirements.txt`:
```
fastapi
uvicorn
langchain
chromadb
sentence-transformers
pydantic
pdfplumber
python-docx
pytesseract
openai
```

---

## 📌 Step D — Frontend (React/Next.js)

Features:
- Chatbot interface (chat bubbles, streaming responses).  
- File upload (new docs).  
- Dashboard for HR/legal to see top queries.  
- Multi-language support (Sinhala/Tamil/English).  

UI Tools: TailwindCSS, shadcn/ui, chart.js/recharts.  

---

## 📌 Step E — Extra Features

- **Document assistant**: Upload a form → bot explains each field.  
- **Action automation**: Generate pre-filled forms, draft letters.  
- **Voice input/output**: Speech-to-text (Whisper) + TTS.  
- **Analytics**: Track FAQs → help HR improve docs.  

---

## 📌 Step F — Deployment

1. **Local dev** → Docker Compose (backend + frontend + vectorDB).  
2. **Cloud** → AWS/GCP/Azure.  
   - Use S3 for docs.  
   - Deploy backend on ECS/Fargate or EC2.  
   - Use API Gateway for routing.  
   - Add Cognito/SSO for authentication.  

---

## 🏆 Hackathon Pitch Tips

- Show **live demo** → chatbot answering real HR/tax questions.  
- Highlight **multi-language support**.  
- Emphasize **compliance + productivity impact** (saves HR/legal time).  
- Bonus: Analytics dashboard to track common employee issues.  

---

## ✅ Next Steps

1. Run `scripts/convert_docs.py` → process your PDFs into `data/processed/`.  
2. Build RAG pipeline (`backend/rag/ingest.py` & `query.py`).  
3. Create FastAPI `/chat` endpoint.  
4. Build React chatbot UI.  
5. Deploy with Docker for hackathon demo.  

---

Happy Hacking 🚀
